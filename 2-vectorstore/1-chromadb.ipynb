{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19455d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65624633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The solar system is a collection of celestial bodies bound together by the gravitational pull of the Sun. At its center lies the Sun, a massive star that provides the light and heat necessary for life on Earth. Surrounding it are eight planets, each with unique characteristics. The inner planets—Mercury, Venus, Earth, and Mars—are rocky and relatively small. The outer planets—Jupiter, Saturn, Uranus, and Neptune—are much larger and composed mostly of gas and ice.\\nIn addition to the planets, the solar system contains moons, asteroids, comets, and dwarf planets like Pluto. The asteroid belt between Mars and Jupiter is home to thousands of rocky bodies, while the Kuiper Belt and Oort Cloud contain icy objects at the edges of the system. Scientists study the solar system to understand not only the origins of Earth but also the possibilities of life beyond our planet.']\n"
     ]
    }
   ],
   "source": [
    "sample_docs=[\"\"\"The solar system is a collection of celestial bodies bound together by the gravitational pull of the Sun. At its center lies the Sun, a massive star that provides the light and heat necessary for life on Earth. Surrounding it are eight planets, each with unique characteristics. The inner planets—Mercury, Venus, Earth, and Mars—are rocky and relatively small. The outer planets—Jupiter, Saturn, Uranus, and Neptune—are much larger and composed mostly of gas and ice.\n",
    "In addition to the planets, the solar system contains moons, asteroids, comets, and dwarf planets like Pluto. The asteroid belt between Mars and Jupiter is home to thousands of rocky bodies, while the Kuiper Belt and Oort Cloud contain icy objects at the edges of the system. Scientists study the solar system to understand not only the origins of Earth but also the possibilities of life beyond our planet.\"\"\"]\n",
    "print(sample_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e9cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample documents created in: /Users/user/Documents/RAGUDEMY/2-vectorstore/data/text_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "# Create a temporary directory (already works in your code)\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Ensure local ./data/text_files folder exists\n",
    "os.makedirs(\"./data/text_files\", exist_ok=True)\n",
    "\n",
    "# Now write files safely\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"./data/text_files/doc_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc)\n",
    "\n",
    "print(f\"Sample documents created in: {os.path.abspath('./data/text_files')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59643961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: /Users/user/Documents/RAGUDEMY/2-vectorstore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4beb20f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n",
      "page_content='Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\n",
      "This session covers real-world security risks in Large Language Model (LLM) deployments, drawn from penetration testing and recent research. Attendees will learn about key vulnerabilities, see a live demo of a novel prompt extraction attack (revealing system prompts without model access), and understand why traditional security tools fall short. The talk also covers how attackers exploit generative AI and provides practical defenses to strengthen AI LLM security posture.\n",
      "\n",
      "Why Attend:\n",
      "\n",
      "Understand common vulnerabilities in LLM applications.\n",
      "\n",
      "Learn from Black Hat trainers and pen testers real-world findings.\n",
      "\n",
      "See live demonstrations of prompt-based attacks.\n",
      "\n",
      "Gain actionable strategies to defend against AI-specific threats.' metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\\nThis session covers real-world security risks in Large Language Model (LLM) deployments, drawn from penetration testing and recent research. Attendees will learn about key vulnerabilities, see a live demo of a novel prompt extraction attack (revealing system prompts without model access), and understand why traditional security tools fall short. The talk also covers how attackers exploit generative AI and provides practical defenses to strengthen AI LLM security posture.\\n\\nWhy Attend:\\n\\nUnderstand common vulnerabilities in LLM applications.\\n\\nLearn from Black Hat trainers and pen testers real-world findings.\\n\\nSee live demonstrations of prompt-based attacks.\\n\\nGain actionable strategies to defend against AI-specific threats.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    path=\"/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,   # <--- force it to use TextLoader\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "print(docs[0])\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940fdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,   # ✅ correct argument\n",
    "    separators=[\"\\n\", \" \", \".\", \"\\n\\n\", \"\\n\\n\\n\"]  # ✅ name should be separators\n",
    ")\n",
    "chunks=text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe8163be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 embeddings created\n",
      "First embedding vector length: 384\n",
      "[[-0.030431121587753296, 0.058468788862228394, -0.052441880106925964, -0.004236826207488775, -0.01571459323167801, -0.11361173540353775, 0.0013876183656975627, 0.06451823562383652, -0.029804306104779243, -0.027357056736946106, -0.1179594099521637, 0.052956949919462204, 0.09355516731739044, -0.010082781314849854, 0.08080901950597763, -0.0072097922675311565, -0.002887786366045475, 0.0020401140209287405, -0.0068238344974815845, -0.05148882418870926, 0.0033004165161401033, 0.06818991154432297, 0.00742182694375515, -0.009852803312242031, -0.0747167095541954, 0.0398201122879982, -2.9867924240534194e-05, 0.0005819569923914969, 0.014980732463300228, -0.024894895032048225, 0.0030398082453757524, 0.10470005869865417, 0.04971923306584358, 0.02541264146566391, 0.027617845684289932, 0.03658105060458183, 0.02491465024650097, -0.08256809413433075, -0.027827631682157516, 0.0027429868932813406, -0.09640645980834961, 0.05136973038315773, -0.04018860682845116, 0.010776105336844921, -0.06180494278669357, 0.03730229288339615, -0.026792993769049644, -0.05762157216668129, -0.027685031294822693, -0.05041204392910004, -0.05669713765382767, 0.029746759682893753, -0.04051460698246956, -0.05769537389278412, -0.015352385118603706, 0.004847770556807518, 0.05637683346867561, 0.00757772009819746, -0.044754717499017715, -0.16046954691410065, -0.03657175600528717, 0.05229435861110687, 0.05201266333460808, 0.08819671720266342, -0.02184869535267353, -0.0003618744376581162, -0.027215395122766495, 0.020703110843896866, 0.059972018003463745, -0.04450058937072754, -0.07724878937005997, -0.03514587879180908, -0.015013284981250763, 0.07473835349082947, 0.013831025920808315, -0.0848022922873497, 0.038533225655555725, -0.00690899882465601, 0.027697036042809486, -0.0073635028675198555, -0.006480020005255938, 0.028413107618689537, -0.014816585928201675, 0.12551946938037872, 0.013520386070013046, -0.022679898887872696, 0.038024164736270905, 0.0571221299469471, 0.007832899689674377, 0.031486764550209045, 0.06074013188481331, -0.04039481282234192, 0.021706566214561462, 0.028199829161167145, 0.011401379480957985, 0.057672690600156784, 0.03441543132066727, -0.05845923349261284, -0.05173473060131073, 0.04391628876328468, -0.014554688706994057, -0.050841525197029114, 0.05270727351307869, -0.015812838450074196, 0.05015440657734871, 0.02527620643377304, 0.05290814861655235, -0.06876098364591599, 0.0420108325779438, -0.03784587234258652, 0.00975431315600872, -0.024103455245494843, -0.034286979585886, -0.04144049063324928, 0.08049052953720093, 0.04384705424308777, -0.04026275873184204, 0.10296279191970825, 0.03560972586274147, 0.027153894305229187, 0.028257543221116066, -0.001673094229772687, 0.017597682774066925, 0.02264411747455597, 0.002449300140142441, -0.031667761504650116, -0.03678157553076744, -1.922580703842354e-33, -0.0825367197394371, -0.060317423194646835, -0.05826300382614136, 0.044312186539173126, 0.08370755612850189, -0.019031254574656487, 0.0981280654668808, 0.043775640428066254, -0.038004498928785324, 0.002545880386605859, -0.030510129407048225, 0.040140170603990555, 0.04821455106139183, 0.10321184992790222, 0.04464871808886528, 0.049358077347278595, 0.02159397304058075, 0.0671750009059906, -0.02043263427913189, -0.006310732569545507, 0.04472403600811958, 0.006295869592577219, 0.0678783506155014, 0.02215268835425377, 0.056887801736593246, -0.0008381585939787328, -0.027416346594691277, -0.02221657894551754, -0.008257245644927025, 0.02836458757519722, -0.12189863622188568, -0.013968421146273613, -0.004817613400518894, 0.013234714046120644, -0.06308116018772125, -0.00822580885142088, -0.055779896676540375, -0.05045565217733383, 0.02893606573343277, -0.025375882163643837, -0.026112884283065796, 0.026508569717407227, 0.02719964273273945, -0.017939558252692223, -0.028106948360800743, 0.020197024568915367, -0.013460018672049046, -0.002750170649960637, -0.08936124294996262, 0.05074629932641983, -0.009289145469665527, -0.0631752461194992, 0.1010822057723999, 0.04456758871674538, -0.02765716053545475, -0.04542309045791626, 0.020302999764680862, -0.006113243289291859, -0.03560471162199974, -0.0658014640212059, 0.009753674268722534, 0.03398530185222626, 0.06557948887348175, 0.004595097620040178, 0.07034214586019516, 0.03153931349515915, 0.02592013031244278, 0.09293673187494278, 0.08050855994224548, 0.036284685134887695, -0.071258544921875, 0.04568731412291527, -0.06649518758058548, 0.048363637179136276, -0.0870230421423912, -0.003470265306532383, 0.06948961317539215, -0.09452034533023834, 0.06811106204986572, 0.06478001177310944, 0.02579559199512005, 0.014295915141701698, 0.029739735648036003, -0.02614540234208107, -0.04099854454398155, -0.0029840688221156597, 0.014492085203528404, 0.025277607142925262, -0.0190567746758461, -0.017872177064418793, -0.033492561429739, -0.11340583860874176, 0.05707975849509239, 0.023521127179265022, -0.005112264771014452, -1.974476483543754e-34, 0.004166497383266687, 0.0026010004803538322, -0.08405198901891708, 0.0024707606062293053, -0.05128036439418793, -0.10899320989847183, 0.015388954430818558, 0.01778274215757847, 0.0196154173463583, 0.042457323521375656, -0.03992380201816559, -0.08218540996313095, 0.08642394840717316, 0.026364432647824287, 0.07133390754461288, 0.016251875087618828, -0.10261855274438858, -0.05995328724384308, -0.0017827970441430807, -0.0008993691299110651, -0.04207220301032066, 0.08085766434669495, -0.09827364236116409, -0.10852662473917007, 0.017359795048832893, -0.01035567931830883, -0.10092879831790924, -0.08481887727975845, 0.055438198149204254, 0.06682538241147995, -0.007273844443261623, 0.01433841697871685, -0.03602806106209755, 0.02835822105407715, 0.05904441699385643, 0.0019064948428422213, 0.03820623457431793, -0.00017858143837656826, 0.026530500501394272, -0.040381480008363724, 0.07587871700525284, 0.04928625002503395, 0.027195708826184273, 0.0605136901140213, 0.0014889325248077512, 0.03534102812409401, -0.0533163845539093, 0.09281489253044128, 0.012237586081027985, -0.08461977541446686, -0.0240937490016222, -0.006893561687320471, 0.056776467710733414, -0.03996835649013519, -0.03245566040277481, -0.041593194007873535, 0.04406822472810745, 0.05181421339511871, -0.06755750626325607, -0.05551285669207573, -0.03924950212240219, -0.046910032629966736, -0.0005748768453486264, 0.0036343398969620466, -0.0789073258638382, 0.058596763759851456, -0.1317332535982132, -0.017598310485482216, -0.06342918425798416, -0.15308436751365662, 0.07498713582754135, -0.050237566232681274, -0.07655494660139084, 0.08435814082622528, -0.07127901911735535, 0.050846539437770844, 0.037584513425827026, -0.058074574917554855, -0.03891321271657944, 0.10356605798006058, 0.053033653646707535, -0.019022280350327492, -0.055342674255371094, 0.07102731615304947, -0.06783951073884964, -0.014903501607477665, -0.07790762931108475, 0.03658678010106087, 0.010591675527393818, 0.0004971746238879859, -0.015373311005532742, 0.062945157289505, -0.00835907831788063, 0.0732303038239479, -0.007696698885411024, -4.083721805159257e-08, -0.016579177230596542, -0.00813504308462143, 0.08319041877985, 0.0659278854727745, 0.006783479359000921, 0.07775861024856567, -0.02790173515677452, -0.04950651526451111, -0.013109581544995308, 0.027850616723299026, -0.02309941127896309, -0.012422037310898304, -0.10002513229846954, -0.05907319486141205, -0.03711174428462982, 0.09504256397485733, -0.02040831372141838, -0.015435614623129368, 0.005228848662227392, 0.0022668074816465378, 0.07081390917301178, -0.04222600907087326, -0.0683041661977768, 0.046350229531526566, -0.040983282029628754, -0.013090090826153755, 0.06882313638925552, 0.01815919205546379, 0.0014156507095322013, -0.06032747030258179, 0.008906458504498005, -0.01955116167664528, -0.012581495568156242, 0.056076232343912125, 0.041651275008916855, 0.04601405933499336, 0.01010159682482481, -0.027337227016687393, 0.034924834966659546, 0.03078281506896019, -0.019709132611751556, -0.02291816473007202, 0.02212655358016491, 0.009282891638576984, -0.015946680679917336, -0.008992818184196949, -0.027037620544433594, -0.04258174076676369, -0.07406529039144516, -0.018561827018857002, -0.021958334371447563, -0.010450039990246296, -0.059595320373773575, 0.012754182331264019, 0.0035921602975577116, 0.08288969844579697, -0.07200969755649567, -0.028111657127738, -0.013143501244485378, 0.02198697440326214, -0.0008660111343488097, 0.15489213168621063, 0.1006268560886383, -0.04640137404203415], [-0.04269081726670265, -0.003888767445459962, 0.019782142713665962, -0.0007176234503276646, 0.05111437663435936, 0.03774630278348923, 0.0493752658367157, 0.007360570598393679, 0.018418563529849052, 0.012537729926407337, -0.033985685557127, -0.027575993910431862, 0.09749465435743332, -0.03989613056182861, 0.0453205443918705, 0.02352050505578518, 0.034789204597473145, -0.01561308465898037, -0.010385516099631786, -0.018312159925699234, -0.04813038930296898, 0.026262015104293823, -0.05078337341547012, 0.0082197654992342, -0.0412435345351696, 0.0010569592704996467, 0.01846746727824211, -0.025079451501369476, 0.002226003911346197, -0.0337289460003376, 0.004194748122245073, 0.06580361723899841, 0.009545484557747841, 0.08439325541257858, -0.011330093257129192, -0.015171435661613941, 0.0006482028984464705, -0.058361202478408813, 0.05329813063144684, -0.07975270599126816, -0.05988756939768791, -0.04235519841313362, 0.03488663583993912, -0.0013395763235166669, 0.02670127898454666, -0.06995078921318054, -0.03086593933403492, -0.018360687419772148, -0.01848132349550724, -0.029100434854626656, -0.03309311345219612, -0.05806483328342438, 0.02957097813487053, 0.010557512752711773, -0.0464007593691349, -0.06235118210315704, 0.04617733135819435, -0.0054647778160870075, 0.01016275305300951, 0.03735602647066116, -0.08021979033946991, -0.02524293027818203, -0.030956164002418518, 0.05397576838731766, -0.000154373818077147, -0.010704312473535538, 0.027676653116941452, 0.11479466408491135, 0.026113662868738174, -0.005148227792233229, -0.017849870026111603, 0.02226647362112999, -0.004275007173418999, 0.005016532726585865, 0.029079319909214973, 0.030383378267288208, -0.024348003789782524, -0.04200024902820587, 0.08755379170179367, -0.08360879123210907, 0.032070789486169815, 0.0033108480274677277, 0.030544087290763855, 0.05451406165957451, 0.021876709535717964, 0.07848256081342697, 0.027117064222693443, -0.052617110311985016, 0.1339246779680252, 0.06932472437620163, -0.005495970603078604, -0.08041500300168991, 0.05946161970496178, 0.09950195252895355, 0.07075387984514236, 0.022913014516234398, 0.009965023957192898, -0.09350530803203583, -0.10812652111053467, 0.07593532651662827, -0.00017939181998372078, 0.026370210573077202, 0.03308044373989105, -0.08888179808855057, -0.011321358382701874, 0.012933299876749516, 0.04530438408255577, -0.05526063218712807, 0.05128984525799751, -0.059015072882175446, 0.02804834395647049, 0.02637212723493576, 0.04000082239508629, -0.060965441167354584, 0.036221977323293686, -0.046512193977832794, 0.05260719358921051, -0.035884540528059006, -0.030851954594254494, 0.0304604172706604, 0.002129413653165102, 0.017514390870928764, 0.00013560695515479892, 0.04000318795442581, 0.015498034656047821, -0.04564286768436432, -0.054273251444101334, 4.376347101012145e-33, 0.024337004870176315, 0.003430186538025737, -0.10051091760396957, 0.05856996402144432, 0.0919409766793251, -0.03189513459801674, 0.04626268520951271, 0.059058696031570435, -0.02844860963523388, -0.05466692894697189, -0.06109791621565819, 0.018904363736510277, 0.013276572339236736, 0.04167051985859871, 0.0715537741780281, 0.06520023196935654, 0.007782591972500086, 0.04808995500206947, 0.013413800857961178, -0.03379366919398308, 0.040991995483636856, -0.05001510679721832, 0.03530791029334068, -0.017204521223902702, 0.040180448442697525, 0.08134160935878754, -0.011311646550893784, -0.010092646814882755, 0.06809429824352264, 0.05664901062846184, -0.08046253770589828, -0.027977388352155685, -0.05836666375398636, 0.025734934955835342, 0.04649760574102402, 0.06014136224985123, -0.03526853397488594, -0.058427803218364716, 0.006747866980731487, 0.003676836611703038, -0.02226683869957924, -0.006284363102167845, -0.005379858426749706, -0.02234167978167534, 0.01869843155145645, -0.03577982261776924, -0.055537860840559006, -0.031656697392463684, -0.010343177244067192, -0.10344938933849335, -0.06859765201807022, 0.023288380354642868, -0.010202793404459953, 0.02877385914325714, -0.03846975415945053, -0.043226342648267746, -0.007679019123315811, -0.020525848492980003, 0.015065249986946583, 0.059738241136074066, -0.07168629765510559, 0.06121087446808815, -0.02164672128856182, 0.05340950936079025, -0.022932859137654305, -0.08107751607894897, -0.05123288184404373, -0.0006749309250153601, 0.051166780292987823, 0.05540938675403595, -0.09123756736516953, -0.026460761204361916, -0.02775127999484539, 0.01231734175235033, -0.1088748648762703, -0.025453446432948112, 0.04850694537162781, -0.00512348860502243, 0.11183828115463257, 0.00415384117513895, -0.008438053540885448, -0.06243160367012024, 0.043104931712150574, 0.023916369304060936, -0.0014620083384215832, 0.008855881169438362, -0.010760730132460594, -0.11755555868148804, -0.056408025324344635, 0.02575579099357128, 0.024733878672122955, -0.07291743159294128, 0.05584872141480446, 0.07671748846769333, -0.027401966974139214, -4.96679240330041e-33, -0.09843184798955917, 0.024234449490904808, -0.10881666839122772, 0.03663656488060951, -0.054755039513111115, -0.06976453214883804, -0.06324321031570435, 0.06223125383257866, -0.05630645900964737, -0.0176435187458992, -0.043227724730968475, 0.017359284684062004, 0.07220463454723358, -0.007454195059835911, 0.10053166002035141, -0.0741988942027092, 0.02675793133676052, -0.0455239862203598, 0.0017026775749400258, 0.011795430444180965, 0.03263850137591362, 0.07626045495271683, -0.09457961469888687, -0.05423879623413086, -0.0005211687530390918, 0.0038454995956271887, -0.04785103723406792, 0.08212357759475708, 0.02314879186451435, 0.10903723537921906, 0.012686909176409245, 0.03786803409457207, -0.05418812856078148, 0.03272450715303421, -0.05168365687131882, 0.07302136719226837, 0.12400131672620773, 0.001952750259079039, 0.0360378623008728, 0.04196406155824661, 0.09543965011835098, -0.050351157784461975, -0.07399346679449081, -0.0032237463165074587, -0.0742177665233612, 0.04795664921402931, -0.019410254433751106, 0.024561993777751923, 0.06897931545972824, -0.05990343168377876, 0.028421100229024887, -0.038318607956171036, 0.04654238000512123, -0.0709393247961998, -0.0721939206123352, -0.05037087947130203, 0.00349469599314034, -0.018065663054585457, 0.015295451506972313, 0.01580481044948101, -0.03900759667158127, -0.001972516067326069, 0.014826657250523567, -0.036700062453746796, -0.028506264090538025, 0.00022408997756429017, -0.05673858895897865, 0.07590735703706741, -0.056739747524261475, -0.061366792768239975, 0.1098857969045639, -0.0037953443825244904, -0.048890262842178345, 0.0695720687508583, 0.004151908680796623, -0.017816564068198204, -0.02357824705541134, -0.09018261730670929, -0.039140041917562485, 0.019434921443462372, 0.06480934470891953, 0.0001393561833538115, -0.0823226049542427, 0.042217571288347244, 0.057876840233802795, 0.0006513617117889225, 0.051179271191358566, 0.046432580798864365, -0.0039365715347230434, 0.021910803392529488, -0.050379034131765366, 0.017559809610247612, -0.05034175142645836, 0.03649846836924553, -0.029109181836247444, -4.191479519022323e-08, -0.03510110825300217, -0.0013312040828168392, 0.046986132860183716, 0.02721262164413929, 0.06962766498327255, 0.024211572483181953, -0.1188446655869484, -0.010860955342650414, 0.024767274037003517, 0.017307337373495102, 0.042682304978370667, -0.01701749674975872, -0.047024887055158615, -0.04355679824948311, -0.00781466905027628, 0.09980781376361847, -0.08351019024848938, 0.0006562495254911482, -0.10768913477659225, -0.10593266785144806, 0.07016050815582275, -0.010820971801877022, 0.02238585613667965, 0.009678211994469166, 0.04732011258602142, 0.0027409575413912535, -0.01617239974439144, 0.0631716325879097, -0.03994196280837059, 0.05414007604122162, -0.0683305561542511, -0.005907138809561729, -0.031725235283374786, 0.05213288962841034, 0.02758183516561985, 0.18564040958881378, -0.01596713624894619, -0.08451918512582779, 0.04167007654905319, -0.01897580921649933, -0.04474249109625816, -0.02290358580648899, 0.02427803911268711, 0.026932792738080025, -0.07582639157772064, -0.019749106839299202, -0.004275107756257057, -0.11153969913721085, 0.04681621864438057, -0.02916453592479229, 0.002266655443236232, -0.05354337766766548, 0.0402304008603096, 0.15857110917568207, 0.004458258394151926, 0.08158471435308456, 0.005322054494172335, -0.06546096503734589, 0.07100579887628555, 0.09522520750761032, 0.03979533165693283, 0.04358617961406708, -0.0009349660249426961, -0.030913395807147026], [-0.002161532174795866, -0.007475966587662697, 0.014229100197553635, -0.007134632673114538, 0.055982425808906555, 0.021365465596318245, 0.045256055891513824, 0.005283834412693977, -0.041576895862817764, 0.0018178781028836966, -0.03491629287600517, -0.04046739637851715, 0.04872499778866768, 0.009564616717398167, 0.05636873096227646, 0.029748540371656418, 0.07773159444332123, -0.009596381336450577, -0.0004972647875547409, -0.03993842378258705, -0.07483188062906265, -0.01449672132730484, 0.011624806560575962, 0.026222892105579376, -0.12258540093898773, 0.0061456020921468735, 0.05235869809985161, -0.03108709678053856, 0.003505172673612833, -0.03556268662214279, 0.007423547096550465, 0.025034183636307716, -0.015301249921321869, 0.060238003730773926, -0.039712294936180115, 0.009750068187713623, 0.02782564051449299, -0.011924440972507, 0.005357603542506695, -0.03947412222623825, -0.03100753389298916, -0.04571114480495453, 0.045034803450107574, -0.03429555147886276, 0.03711170330643654, -0.01678355224430561, 0.02593553066253662, -0.012956437654793262, -0.04452640190720558, -0.02385210432112217, 0.006006650160998106, -0.0405823178589344, 0.03018040396273136, -0.02269008755683899, -0.033666595816612244, -0.02155604213476181, 0.08136072009801865, 0.047608669847249985, -0.0030337870121002197, -0.02305079624056816, 0.010551459155976772, -0.05478428676724434, -0.03299664705991745, 0.04077737778425217, -0.002113722264766693, 0.04566555842757225, 0.010966098867356777, 0.12845957279205322, 0.058608852326869965, -0.03812213987112045, -0.011223298497498035, -0.00601971847936511, -0.031707748770713806, 0.049718789756298065, 0.017013106495141983, 0.03907390683889389, -0.011098592542111874, -0.029761923477053642, 0.13885042071342468, -0.006531441118568182, 0.009206047281622887, -0.014516829513013363, -0.010978086851537228, 0.13435503840446472, 0.061176612973213196, 0.06271158158779144, 0.0028407888021320105, -0.0077900877222418785, 0.0768667608499527, 0.04435138404369354, 0.05101313441991806, -0.015342562459409237, -0.03543657436966896, 0.03652045130729675, 0.07321509718894958, 0.02822769805788994, -0.01675429753959179, -0.0956743136048317, -0.06549417227506638, 0.07650233805179596, -0.01584104634821415, 0.0030141896568238735, -0.013152219355106354, -0.027562014758586884, -0.004986668936908245, -0.00297245173715055, 0.03851291909813881, -0.06395372003316879, 0.07785664498806, -0.020313216373324394, 0.026406606659293175, 0.015903383493423462, 0.07818270474672318, -0.005113336723297834, 0.08978084474802017, -0.04893152788281441, -0.011295478790998459, 0.0328742191195488, 0.002298790030181408, 0.07900802791118622, -0.011271246708929539, 0.042019471526145935, -0.02850945293903351, 0.02816096693277359, 0.05089660361409187, -0.05164910852909088, -0.08804616332054138, 2.9507437355203608e-33, 0.02489994652569294, 0.01489092968404293, -0.033535465598106384, 0.07515499740839005, 0.0741487368941307, -0.06021726131439209, 0.05335835739970207, 0.0695294588804245, 0.00242532673291862, 0.007996030151844025, 0.0119782704859972, 0.06056801229715347, 0.04714541137218475, 0.023482078686356544, 0.025531833991408348, 0.06752555817365646, -0.051391370594501495, 0.02002449706196785, -0.03184642270207405, -0.0301913283765316, 0.02338959276676178, -0.09948674589395523, 0.0226083155721426, -0.032422903925180435, 0.02699614316225052, 0.06300412863492966, -0.010360741056501865, 0.007503740023821592, 0.13754843175411224, 0.03410548344254494, -0.05151304602622986, 0.015218828804790974, -0.10529761761426926, -0.029477842152118683, 0.04478044807910919, 0.06545092910528183, -0.06055344641208649, -0.04784712567925453, -0.014862325973808765, -0.012439883314073086, -0.07091540843248367, -0.0013319967547431588, -0.008756929077208042, -0.01948881894350052, 0.06265750527381897, 0.01406160555779934, 0.00891871191561222, -0.12206905335187912, -0.016333503648638725, -0.06958608329296112, -0.09053052216768265, -0.025427894666790962, -0.07249455899000168, -0.03831863030791283, -0.04713815078139305, -0.06562440097332001, -0.021626394242048264, -0.020597446709871292, -0.03947147727012634, 0.039097465574741364, -0.05220286175608635, 0.07520186901092529, -0.04813935235142708, 0.061588868498802185, -0.12552279233932495, -0.0750640258193016, -0.05939818546175957, -0.030922990292310715, 0.0491662323474884, -0.011347057297825813, -0.021030990406870842, 0.008537226356565952, 0.004764029756188393, -0.009459446184337139, -0.13397696614265442, -0.06394384056329727, 0.025464555248618126, 0.004813183099031448, 0.10259834676980972, -0.014532019384205341, 0.04911436140537262, -0.01888655312359333, -0.0031898710876703262, 0.015543673187494278, 0.035001590847969055, -0.017210323363542557, -0.019081799313426018, -0.1099853441119194, -0.02058457024395466, 0.06491480022668839, -0.013380119577050209, -0.04144536331295967, 0.028291618451476097, 0.11446160078048706, -0.060023367404937744, -2.284154317289643e-33, -0.0800134614109993, 0.046327296644449234, -0.051284193992614746, 0.08668288588523865, 0.02482086978852749, -0.005739277228713036, -0.07238523662090302, 0.01385018602013588, 0.011699015274643898, 0.044693417847156525, -0.04932020232081413, 0.03105830028653145, 0.008317109197378159, 0.05743178725242615, 0.01456091646105051, -0.12218198925256729, 0.005868537817150354, 0.012363133952021599, 0.008890203200280666, -0.05594009906053543, 0.03451159596443176, 0.07436712086200714, -0.06729867309331894, -0.07096019387245178, -0.0209139883518219, 0.011622138321399689, -0.007972082123160362, 0.040103279054164886, 0.03226258233189583, 0.09007095545530319, 0.07197451591491699, 0.04806237667798996, -0.03512101620435715, 0.026321925222873688, -0.046820368617773056, 0.10246137529611588, 0.10123734921216965, 0.012541612610220909, 0.029610592871904373, 0.032296355813741684, 0.09926209598779678, -0.07234945893287659, -0.018206272274255753, -0.01468008104711771, -0.025466812774538994, 0.04328669607639313, -0.003535471623763442, 0.0147832240909338, 0.07337968051433563, -0.07477997243404388, 0.014439820311963558, -0.07368814200162888, 0.0667237713932991, -0.04820326343178749, -0.057154178619384766, 0.00017925971769727767, 0.0561259426176548, -0.055423393845558167, -0.008930946700274944, 0.024197515100240707, -0.038264576345682144, 0.013195754960179329, 0.014519806951284409, 0.0357896126806736, -0.035944242030382156, -0.00932867918163538, -0.05385734885931015, 0.11961079388856888, -0.05969079211354256, -0.04933175817131996, 0.051935356110334396, 0.03376156836748123, -0.015638627111911774, 0.004038571380078793, -0.04517239332199097, -0.04064406827092171, -0.0430733859539032, -0.04809655621647835, -0.04576839879155159, -0.0006612203433178365, 0.024228187277913094, -0.052712079137563705, -0.04844921827316284, 0.07886027544736862, -0.015896648168563843, 0.14065128564834595, 0.07795672863721848, 0.03460169583559036, 0.0040406822226941586, -0.049531400203704834, -0.07277180999517441, 0.027262013405561447, -0.027805574238300323, -0.021860504522919655, -0.013333405368030071, -3.5258782560276813e-08, -0.04968244954943657, -0.04848482087254524, 0.07335889339447021, 0.030426055192947388, -0.02471640706062317, 0.035876400768756866, -0.14142990112304688, 0.016948333010077477, 0.02812814712524414, 0.0261897724121809, 0.0013801775639876723, -0.06512244045734406, -0.08342356234788895, -0.013661923818290234, 0.08687349408864975, 0.03766709566116333, -0.02113143727183342, 0.002388641471043229, -0.08384843915700912, -0.05899384245276451, 0.0652720183134079, -0.017867187038064003, 0.035903312265872955, 0.0031264834105968475, 0.03572763875126839, -0.0447225496172905, 0.041852932423353195, 0.09368717670440674, -0.013606961816549301, 0.08898844569921494, -0.06294533610343933, -0.016259506344795227, -0.0003503133775666356, -0.004881225060671568, 0.003634008811786771, 0.053226735442876816, 0.004380168858915567, -0.09135059267282486, 0.08819012343883514, -0.018192773684859276, -0.10908716171979904, -0.011236093007028103, 0.05900166928768158, 0.015539797954261303, -0.0700216144323349, -0.009369059465825558, -0.02834429033100605, -0.07497629523277283, -0.014990916475653648, -0.025837475433945656, 0.00699933897703886, -0.048452313989400864, 0.02802112139761448, 0.11363985389471054, 0.054522380232810974, 0.06848309189081192, 0.0017711636610329151, -0.0708644911646843, 0.008015463128685951, 0.09000424295663834, 0.06158684566617012, 0.05364031717181206, -0.11501494795084, -0.0015594020951539278]]\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# init embeddings\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# convert Document objects -> list of strings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "# generate embeddings\n",
    "vector = embeddings_model.embed_documents(texts)\n",
    "\n",
    "print(len(vector), \"embeddings created\")\n",
    "print(\"First embedding vector length:\", len(vector[0]))\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4f63f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created:3\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "vectorstore=Chroma.from_documents(documents=chunks, embedding=embeddings_model, persist_directory=persist_directory,collection_name=\"rag\")\n",
    "print(f\"Vectorstore created:{vectorstore._collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d06c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'rag' deleted ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/q0vghxyj0cs6_3glp9q55pq80000gp/T/ipykernel_38192/2904532259.py:6: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Connect to your persisted DB\n",
    "db = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag\",\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "# Now delete the collection\n",
    "db._client.delete_collection(\"rag\")\n",
    "print(\"Collection 'rag' deleted ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ecf994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Score: -0.2087\n",
      "Content: Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language const...\n",
      "\n",
      "Result 2:\n",
      "Score: -0.3557\n",
      "Content: This session covers real-world security risks in Large Language Model (LLM) deployments, drawn from penetration testing and recent research. Attendees will learn about key vulnerabilities, see a live ...\n",
      "\n",
      "Result 3:\n",
      "Score: -0.4231\n",
      "Content: Why Attend:\n",
      "\n",
      "Understand common vulnerabilities in LLM applications.\n",
      "\n",
      "Learn from Black Hat trainers and pen testers real-world findings.\n",
      "\n",
      "See live demonstrations of prompt-based attacks.\n",
      "\n",
      "Gain actionab...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/q0vghxyj0cs6_3glp9q55pq80000gp/T/ipykernel_38192/305248199.py:3: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\"), -0.20873385171617498), (Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content='This session covers real-world security risks in Large Language Model (LLM) deployments, drawn from penetration testing and recent research. Attendees will learn about key vulnerabilities, see a live demo of a novel prompt extraction attack (revealing system prompts without model access), and understand why traditional security tools fall short. The talk also covers how attackers exploit generative AI and provides practical defenses to strengthen AI LLM security posture.\\n\\nWhy Attend:\\n\\nUnderstand common vulnerabilities in LLM applications.'), -0.3556847396081986), (Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content='Why Attend:\\n\\nUnderstand common vulnerabilities in LLM applications.\\n\\nLearn from Black Hat trainers and pen testers real-world findings.\\n\\nSee live demonstrations of prompt-based attacks.\\n\\nGain actionable strategies to defend against AI-specific threats.'), -0.42309306041737016)]\n",
      "  results_scores = vectorstore.similarity_search_with_relevance_scores(query, k=3)\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the solar system?\"\n",
    "\n",
    "results_scores = vectorstore.similarity_search_with_relevance_scores(query, k=3)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_scores, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f90a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-C6YdiiSjgLnuq5qNvl16C21jGXvYa', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--e5638dd6-fb0a-44f4-b73a-96108ce588b7-0' usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ⚠️ Replace with your actual OpenAI key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.4)\n",
    "response = llm.invoke(\"Hello, how are you?\")\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335045b",
   "metadata": {},
   "source": [
    "Modern rag chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0b071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings_model, persist_directory=\"./chroma_db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8639a036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x153437260>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ed26ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "system_prompt = \"\"\"\n",
    "You are a QA assistant that answers questions strictly using the retrieved documents or data provided.\n",
    "\n",
    "Rules:\n",
    "1. Answer only based on the retrieved information.\n",
    "2. If the answer is not found or only partially matches the question, respond clearly: \"Out of context.\"\n",
    "3. Provide concise answers and quote or reference the relevant part of the retrieved data whenever possible.\n",
    "4. Do not make assumptions or invent information.\n",
    "5. Maintain a professional, clear, and friendly tone.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52718d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a QA assistant that answers questions strictly using the retrieved documents or data provided.\\n\\nRules:\\n1. Answer only based on the retrieved information.\\n2. If the answer is not found or only partially matches the question, respond clearly: \"Out of context.\"\\n3. Provide concise answers and quote or reference the relevant part of the retrieved data whenever possible.\\n4. Do not make assumptions or invent information.\\n5. Maintain a professional, clear, and friendly tone.\\n\\nContext:\\n{context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ade3911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a QA assistant that answers questions strictly using the retrieved documents or data provided.\\n\\nRules:\\n1. Answer only based on the retrieved information.\\n2. If the answer is not found or only partially matches the question, respond clearly: \"Out of context.\"\\n3. Provide concise answers and quote or reference the relevant part of the retrieved data whenever possible.\\n4. Do not make assumptions or invent information.\\n5. Maintain a professional, clear, and friendly tone.\\n\\nContext:\\n{context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x309d831a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x337e5ac60>, root_client=<openai.OpenAI object at 0x309b91580>, root_async_client=<openai.AsyncOpenAI object at 0x309d81550>, temperature=0.4, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b419e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x153437260>, search_kwargs={'k': 2}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nYou are a QA assistant that answers questions strictly using the retrieved documents or data provided.\\n\\nRules:\\n1. Answer only based on the retrieved information.\\n2. If the answer is not found or only partially matches the question, respond clearly: \"Out of context.\"\\n3. Provide concise answers and quote or reference the relevant part of the retrieved data whenever possible.\\n4. Do not make assumptions or invent information.\\n5. Maintain a professional, clear, and friendly tone.\\n\\nContext:\\n{context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x309d831a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x337e5ac60>, root_client=<openai.OpenAI object at 0x309b91580>, root_async_client=<openai.AsyncOpenAI object at 0x309d81550>, temperature=0.4, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "rag_chain=create_retrieval_chain(retriever,document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cc66585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is python ?',\n",
       " 'context': [Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\"),\n",
       "  Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\")],\n",
       " 'answer': '\"Python is an interpreted, high-level and general-purpose programming language. Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace.\"'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is python ?\"})\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90e58815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Python is an interpreted, high-level and general-purpose programming language. Python\\'s design philosophy emphasizes code readability with its notable use of significant whitespace.\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71aa149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x153437260>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1bc04",
   "metadata": {},
   "source": [
    "LCEL chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a632877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b71fa664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='You are a helpful QA assistant. \\n\\n- Answer only using the provided context.  \\n- If the answer is not in the context, reply: \"Out of context.\"  \\n- Keep your answers short, clear, and professional.  \\n\\nContext:\\n{context} \\n\\nQuestion: {question}\\nAnswer:\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_prompt= ChatPromptTemplate.from_template(\"\"\"You are a helpful QA assistant. \n",
    "\n",
    "- Answer only using the provided context.  \n",
    "- If the answer is not in the context, reply: \"Out of context.\"  \n",
    "- Keep your answers short, clear, and professional.  \n",
    "\n",
    "Context:\n",
    "{context} \n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\")  \n",
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb4f7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0bf4aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python is an interpreted, high-level and general-purpose programming language.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel=(\n",
    "    {\"context\":retriever | format_docs,\"question\": RunnablePassthrough()}\n",
    "    |custom_prompt\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")\n",
    "response=rag_chain_lcel.invoke(\"What is the python?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3a8e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\"),\n",
       " Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content='This session covers real-world security risks in Large Language Model (LLM) deployments, drawn from penetration testing and recent research. Attendees will learn about key vulnerabilities, see a live demo of a novel prompt extraction attack (revealing system prompts without model access), and understand why traditional security tools fall short. The talk also covers how attackers exploit generative AI and provides practical defenses to strengthen AI LLM security posture.\\n\\nWhy Attend:\\n\\nUnderstand common vulnerabilities in LLM applications.'),\n",
       " Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content='Why Attend:\\n\\nUnderstand common vulnerabilities in LLM applications.\\n\\nLearn from Black Hat trainers and pen testers real-world findings.\\n\\nSee live demonstrations of prompt-based attacks.\\n\\nGain actionable strategies to defend against AI-specific threats.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d51bf85",
   "metadata": {},
   "source": [
    "Conversational memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20eccf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88a8783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt=\"\"\"Given a chat history and latest user question which might reference context in chat history,formulate \n",
    "a standalone question which can be understood without the chat history.Do not answer the question,\n",
    "just reformulate it if needed and otherwise return as it is\"\"\"\n",
    "contextualize_q_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",contextualize_q_system_prompt),MessagesPlaceholder(\"chat_history\"),(\"human\",\"{input}\"),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8d330d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x309d831a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x337e5ac60>, root_client=<openai.OpenAI object at 0x309b91580>, root_async_client=<openai.AsyncOpenAI object at 0x309d81550>, temperature=0.4, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47ab9cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x153437260>, search_kwargs={'k': 2}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x113c4f9c0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and latest user question which might reference context in chat history,formulate \\na standalone question which can be understood without the chat history.Do not answer the question,\\njust reformulate it if needed and otherwise return as it is'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x309d831a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x337e5ac60>, root_client=<openai.OpenAI object at 0x309b91580>, root_async_client=<openai.AsyncOpenAI object at 0x309d81550>, temperature=0.4, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x153437260>, search_kwargs={'k': 2})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever=create_history_aware_retriever(llm,retriever,contextualize_q_prompt)\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a7d06fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt=\"\"\"you are an assistant for question-answering task.\n",
    "use the folowing pieces of retrieved context to answer the question.\n",
    "if you dont know the answer,just say that you don't know.Use three sentences maximum and keep the answer concise\n",
    "\n",
    "Context:{context}\"\"\"\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),(\"human\",\"{input}\"),\n",
    "])\n",
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39214660",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain=create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    question_answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c349d1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is an interpreted, high-level and general-purpose programming language known for its emphasis on code readability and significant whitespace. It aims to help programmers write clear, logical code for projects of various scales.\n"
     ]
    }
   ],
   "source": [
    "chat_history=[]\n",
    "result1=conversational_rag_chain.invoke({\"chat_history\":chat_history,\n",
    "\"input\":\"what is python?\"})\n",
    "\n",
    "print(result1['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([HumanMessage(content=\"what is python\"),\n",
    "AIMessage(content=result1['answer'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab073b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='what is python', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Python is an interpreted, high-level and general-purpose programming language known for its emphasis on code readability and significant whitespace. It aims to help programmers write clear, logical code for projects of various scales.', additional_kwargs={}, response_metadata={})],\n",
       " 'input': 'what are its main types?',\n",
       " 'context': [Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\"),\n",
       "  Document(metadata={'source': '/Users/user/Documents/RAGUDEMY/0-DataIngestParsing/data/text_files/python.txt'}, page_content=\"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.AI LLM Security Session Summary\")],\n",
       " 'answer': 'Python is an interpreted, high-level, and general-purpose programming language that emphasizes code readability and uses significant whitespace. Its main types include integers, floats, strings, lists, tuples, dictionaries, and sets.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2=conversational_rag_chain.invoke({\n",
    "    \"chat_history\":chat_history,\n",
    "    \"input\":\"what are its main types?\"\n",
    "})\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a4fa9",
   "metadata": {},
   "source": [
    "LCEL:groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fd23b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x3053119a0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x305311df0>, model_name='gemm2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=init_chat_model(model=\"groq:gemm2-9b-it\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_prompt=ChatPromptTemplate.from_template(\"\"\"Answer the question based only on following context:\n",
    "context:{context}\n",
    "question:{question}\n",
    "Answer:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90839c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
